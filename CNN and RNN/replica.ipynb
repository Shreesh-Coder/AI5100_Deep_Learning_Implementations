{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4494, 1.0000],\n",
      "        [0.2620, 1.0000]], dtype=torch.float64) tensor([0.7114], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8999)\n",
    "torch.manual_seed(8999)\n",
    "# Here I have define the simple input arrays \n",
    "X,Y = [],[]\n",
    "\n",
    "# Length of indivisual data point \n",
    "LOW_LIM = 2\n",
    "UPR_LIM = 9\n",
    "\n",
    "# I have taken the 5000 data points\n",
    "for _ in range(5000):\n",
    "  # Randomly select length\n",
    "  LEN = np.random.randint(LOW_LIM,UPR_LIM)\n",
    "  # Random points of selected size, value between one and zero\n",
    "  D1 = np.random.random((LEN)).astype(np.double)\n",
    "  D2 = np.zeros(LEN)\n",
    "  # Randomly seet 2 positions as one.\n",
    "  ONEs = np.random.randint(LEN,size=(2))\n",
    "  while ONEs[0] == ONEs[1]:\n",
    "    ONEs = np.random.randint(LEN,size=(2))\n",
    "  D2[ONEs] = 1\n",
    "  \n",
    "  # Append to Data array after coverting to tensor.\n",
    "  X.append(torch.from_numpy(np.array([(D1[i] , D2[i]) for i in range(LEN)])).double())\n",
    "  Y.append(torch.from_numpy(np.array([ D1[ONEs[0]] + D1[ONEs[1]] ])))\n",
    "\n",
    "print(X[0], Y[0])\n",
    "# Converting to numpy array\n",
    "# X = np.array(X)\n",
    "# Y = np.array(Y)\n",
    "\n",
    "# # Printing the shapes\n",
    "# X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(number_samples: int, max_len_input_sequence: int) -> tuple[list, list]:\n",
    "    # Initialize lists to store sequences and their corresponding sums\n",
    "    sequences = []\n",
    "    sums = []\n",
    "    \n",
    "    for _ in range(number_samples):\n",
    "        # Generate a random sequence length\n",
    "        seq_len = np.random.randint(2, max_len_input_sequence + 1)\n",
    "        \n",
    "        # Create the sequence with random values in the first dimension\n",
    "        sequence = np.zeros((seq_len, 2))\n",
    "        sequence[:, 0] = np.random.rand(seq_len)\n",
    "        \n",
    "        # Randomly choose two distinct positions for the markers\n",
    "        markers = np.random.choice(seq_len, 2, replace=False)\n",
    "        sequence[markers, 1] = 1\n",
    "        \n",
    "        # Calculate the sum of the marked values\n",
    "        sum_values = np.sum(sequence[markers, 0])\n",
    "        \n",
    "        # Append the sequence and its sum to the respective lists\n",
    "        sequences.append(sequence)\n",
    "        sums.append(sum_values)\n",
    "    \n",
    "    # Convert lists to NumPy arrays for efficient processing in training\n",
    "    sequences = np.array(sequences, dtype=object)  # Use dtype=object for variable-length sequences\n",
    "    sums = np.array(sums)\n",
    "    \n",
    "    return sequences, sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61347943 0.        ]\n",
      " [0.54902338 1.        ]\n",
      " [0.23564526 1.        ]\n",
      " [0.77829807 0.        ]]\n",
      "Sum: 0.7846686428125885\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "sequences, sums = data_generator(5000, 20)\n",
    "\n",
    "# Example usage: print the first sample\n",
    "print(sequences[0])\n",
    "print(\"Sum:\", sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train split of 33 - 66\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the device\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is implementation of ElmonRNN \n",
    "# I have followed above equations & figure to implement.\n",
    "class ElmonRNN(nn.Module):\n",
    "  def __init__(self, INP_S, HID_S, OUT_S):\n",
    "    super().__init__()\n",
    "\n",
    "    self.U = nn.Linear(INP_S, HID_S  , bias=False )\n",
    "    self.W = nn.Linear(HID_S, HID_S)\n",
    "    self.V = nn.Linear(HID_S, OUT_S)\n",
    "    \n",
    "    self.double()\n",
    "\n",
    "  def forward(self, INP, HID_State):\n",
    "    Ux = self.U(INP)\n",
    "\n",
    "    Wh = self.W(HID_State)\n",
    "    Ht = torch.tanh(Ux + Wh)\n",
    "\n",
    "    OUT = self.V(Ht)\n",
    "    return OUT, Ht\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElmonRNN(\n",
      "  (U): Linear(in_features=2, out_features=10, bias=False)\n",
      "  (W): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (V): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(8999)\n",
    "# Initializing perameters \n",
    "MAX_EPOCH = 25\n",
    "INP_S  = 2\n",
    "HID_S  = 10\n",
    "OUT_S  = 1\n",
    "L      = 0.005\n",
    "Model1 = ElmonRNN(INP_S, HID_S, OUT_S).to(device)\n",
    "\n",
    "print(Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Empty dictionary to save data to plot later\n",
    "TRAIN_LOSS_HIST = {}\n",
    "\n",
    "# Defined a loss function as MSE\n",
    "MSE_LOSS = nn.MSELoss()\n",
    "\n",
    "# Defined OPTIMIZER as Adam\n",
    "OPTIMIZER = torch.optim.Adam(Model1.parameters(), lr = L)\n",
    "\n",
    "# Run till MaxEpoch8\n",
    "for epoch in tqdm(range(MAX_EPOCH)):\n",
    "  # Empty Temp dicts\n",
    "  EPOCH_LOSS_HIST = list()\n",
    "  # Iter over data set [SGD]\n",
    "  for X_, Y_ in zip(X_train,y_train):\n",
    "    # Setting gradients to zero\n",
    "    Model1.zero_grad()\n",
    "    # Intializing Loss\n",
    "    loss = 0\n",
    "    # Intializing perameter to pass in forwardpass \n",
    "    HID =  torch.zeros(1, HID_S, requires_grad=False,dtype=torch.float64).to(device)\n",
    "    X_, Y_ = X_.to(device), Y_.to(device)\n",
    "    OUT = 0\n",
    "    # Iter over current Input Sequence\n",
    "    for i in range(X_.shape[0]):\n",
    "      OUT, HID = Model1(X_[i,:], HID)\n",
    "    # finding loss on last output.\n",
    "    loss = MSE_LOSS(OUT, Y_)\n",
    "    # Calling Backward on final loss\n",
    "    loss.backward()\n",
    "    # Cliping the gradient to prevent exploding gradients\n",
    "    nn.utils.clip_grad_norm_(Model1.parameters(), 3)\n",
    "    # Updating model perameters\n",
    "    OPTIMIZER.step()\n",
    "    # Saving currunt loss\n",
    "    EPOCH_LOSS_HIST.append(loss.detach().item())\n",
    "  # Saving avg loss over whole dataset\n",
    "  TRAIN_LOSS_HIST[epoch] = torch.tensor(EPOCH_LOSS_HIST).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
